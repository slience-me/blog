---
layout: post
title: 机器学习｜【机器学习合集】模型设计之分组网络
categories: [机器学习]
description: 【机器学习合集】模型设计之分组网络
keywords: 机器学习
mermaid: false
sequence: false
flow: false
mathjax: false
mindmap: false
mindmap2: false
---

![img](https://raw.githubusercontent.com/slience-me/picGo/master/images/logo_slienceme3.jpeg)

本文作者： [slience_me](https://slienceme.cn/)

---

# 分组网络

> - 分组卷积网络（Grouped Convolutional Network），有时称为分组卷积或通道分组卷积，是一种用于神经网络模型设计的技术。它的核心思想是将输入数据的通道（通常是输入特征图的通道）分成多个组，然后在每个组内进行卷积操作，以减小模型的参数数量和计算复杂度。以下是分组卷积网络的一些关键特点：

> 1. `通道分组`：
>    - 通常，输入特征图的通道会被均匀地分成若干组，每个组包含一部分通道。这样，每个组内的通道将分别进行卷积操作。
>    - 通道分组的数量可以根据任务和设计需求来设置。分组越多，模型的参数数量和计算复杂度就越小，但可能会损失一些特征的信息。
>    - 分组卷积网络通常用于卷积神经网络（Convolutional Neural Networks，CNN）中，但也可以用于其他神经网络架构。
> 2. `参数共享`：
>    - 在分组卷积中，每个组内的卷积层共享权重，这意味着相同组内的不同通道之间的特征是共享的。这有助于减小模型的参数数量。
>    - 不同组之间的卷积操作通常使用不同的权重，以保留不同组内的特征差异。
> 3. `减小计算复杂度`：
>    - 分组卷积网络可以显著减小模型的计算复杂度，特别是在通道数量较大的情况下。
>    - 这对于嵌入式系统、移动设备和需要轻量级模型的应用非常有用。
> 4. `特定任务和设计需求`：
>    - 分组卷积网络通常用于特定的设计需求，例如，当模型的参数数量需要受到限制时，或者当需要在计算和存储资源受限的环境中部署模型时。
>    - 它们也可以用于图像分割、物体检测、分类等计算机视觉任务。

> - 总之，分组卷积网络是一种用于降低模型参数数量和计算复杂度的技术。它可以根据任务的需求在通道之间引入分组，从而在保留一定特征信息的同时减小计算资源的需求。这种技术特别适用于嵌入式设备和轻量级神经网络模型的设计。

## 1. 什么是分组网络

### 1.1 卷积拆分的使用

-  <font color=#E91E63>**高维卷积拆分为低维卷积，”Flattened convolutional neural networks for feedforward acceleration“**</font>
![Alt Text](/images/posts/9a686911fe074864b78f7a8b7d47cbec.png)
### 1.2  通道分离卷积的来源

-  <font color=#E91E63>**Laurent Sifre在 “Rigid-Motion Scattering for Texture Classification”提出了depthwise separable convolution**</font>
![Alt Text](/images/posts/0add08888f1844548ecdd4776528e2b7.png)
### 1.3 GoogLeNet/Inception

-  <font color=#E91E63>**GoogleNet取得了2014年ImageNet分类大赛的冠军，参数量远小于VGG系列网络，而精度和速度则超越了VGG系列**</font>
![Alt Text](/images/posts/953b0a090b354b36b0d9045a254d9bff.png)
### 1.4 从Inception到Xception(extreme inception)

-  <font color=#E91E63>**Xception发展到极致**</font>
![Alt Text](/images/posts/380ba08d3f484869a3942e1190a6feca.png)
### 1.5 通道分组卷积模型基准MobileNet

-  <font color=#E91E63>**移动端高效率模型，与Xception中的不同是1×1卷积放置在分组卷积之后**</font>
![Alt Text](/images/posts/c270f62b6f8a49a4a18dac822292f677.png)
## 2. 不同通道分组策略
### 2.1 打乱重组的分组
-  <font color=#E91E63>**直接分组使得不同通道之间没有交流，导致信息的丢失，ShuffleNet增加了通道的信息交换，使得各个组的信息更丰富**</font>
![Alt Text](/images/posts/eec3e2a85d2f409099d03c0a22553686.png)
### 2.2 多尺度卷积核分组

-  <font color=#E91E63>**SqueezeNet**</font>
![Alt Text](/images/posts/99d7bd2b30454de69cc3c8019c7d33c3.png)
### 2.3 多分辨率卷积分组

-  <font color=#E91E63>**Big-Little Net将通道分解为多分辨率，大分辨率使用更少的通道数**</font>
![Alt Text](/images/posts/bf0c773886714a34ac8a8f198102fea3.png)
-  <font color=#E91E63>**Octive convolution将通道分解为低频+高频分量，低频使用更小的分辨率**</font>
![Alt Text](/images/posts/5ed5716354ca4b62a17a3ddaf7c8040d.png)
### 2.4 分数+整数的分组卷积

-  <font color=#E91E63>**DSConv : Efficient Convolution Operator**</font>
![Alt Text](/images/posts/5c0ffd4dedaf424f918a07cd68758e53.png)
![Alt Text](/images/posts/da333024b44e43c7b7f8f33cc408f3cf.png)
### 2.5 级连分组卷积

-  <font color=#E91E63>**Interleaved Group Convolutions**</font>
![Alt Text](/images/posts/0e773b19416a4c9da1409d3ec2da963c.png)
## 3. 可学习的分组网络
### 3.1 卷积核配置的学习
-  <font color=#E91E63>**MixNet与ScaleNet**</font>
![Alt Text](/images/posts/c88dd127f52046279781bcacb65d50ae.png)
### 3.2 分组连接的学习

-  <font color=#E91E63>**CondenseNet**</font>
![Alt Text](/images/posts/4571d413b070419695ea2f3f1594274c.png)
-  <font color=#E91E63>**Dynamic Group Convolution(DGC)**</font>
![Alt Text](/images/posts/1f79d446ba3f4efa8ba69f070606a6c9.png)

**注意：部分内容来自阿里云天池**
