<!DOCTYPE html> <html lang="zh-cmn-Hans" prefix="og: http://ogp.me/ns#" class="han-init"> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" /> <title>机器学习｜【机器学习合集】模型设计之注意力机制 &mdash; Slience_me的博客</title> <link rel="stylesheet" href="https://blog.slienceme.cn/assets/vendor/primer-css/css/primer.css"> <link rel="stylesheet" href="https://blog.slienceme.cn/assets/css/components/collection.css"> <link rel="stylesheet" href="https://blog.slienceme.cn/assets/css/components/repo-card.css"> <link rel="stylesheet" href="https://blog.slienceme.cn/assets/css/sections/repo-list.css"> <link rel="stylesheet" href="https://blog.slienceme.cn/assets/css/components/boxed-group.css"> <link rel="stylesheet" href="https://blog.slienceme.cn/assets/css/globals/common.css"> <link rel="stylesheet" href="https://blog.slienceme.cn/assets/css/globals/responsive.css"> <link rel="stylesheet" href="https://blog.slienceme.cn/assets/css/posts/index.css"> <link rel="stylesheet" href="https://blog.slienceme.cn/assets/vendor/octicons/octicons/octicons.css"> <link rel="stylesheet" href=" https://cdn.jsdelivr.net/npm/@docsearch/css@3 "/> <link rel="stylesheet" href="https://mazhuang.org/rouge-themes/dist/github.css"> <link rel="stylesheet" href="https://blog.slienceme.cn/assets/vendor/share.js/dist/css/share.min.css"> <link rel="canonical" href="https://blog.slienceme.cn/2023/10/31/%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6&%E5%8A%A8%E6%80%81%E7%BD%91%E7%BB%9C/"> <link rel="alternate" type="application/atom+xml" title="Slience_me的博客" href="https://blog.slienceme.cn/feed.xml"> <link rel="shortcut icon" href="https://blog.slienceme.cn/favicon.ico"> <meta property="og:title" content="机器学习｜【机器学习合集】模型设计之注意力机制"> <meta name="keywords" content="机器学习"> <meta name="og:keywords" content="机器学习"> <meta name="description" content=""> <meta name="og:description" content=""> <meta property="og:url" content="https://blog.slienceme.cn/2023/10/31/%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6&%E5%8A%A8%E6%80%81%E7%BD%91%E7%BB%9C/"> <meta property="og:site_name" content="Slience_me的博客"> <meta property="og:type" content="article"> <meta property="og:locale" content="zh_CN" /> <meta property="article:published_time" content="2023-10-31"> <meta name="google-site-verification" content="2feHjT1GNs1Yi2JQfOtdYx7d048naG_-cMwZaDAopIA" /> <script src="https://blog.slienceme.cn/assets/vendor/jquery/dist/jquery.min.js"></script> <script src="https://blog.slienceme.cn/assets/js/main.js"></script> </head> <body class="" data-mz=""> <header class="site-header"> <div class="container"> <h1><a href="https://blog.slienceme.cn/" title="Slience_me的博客"><span class="octicon octicon-mark-github"></span> Slience_me的博客</a></h1> <button class="collapsed mobile-visible" type="button" onclick="toggleMenu();"> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button> <nav class="site-header-nav" role="navigation"> <a href="https://blog.slienceme.cn/" class="site-header-nav-item" target="" title="首页">首页</a> <a href="https://blog.slienceme.cn/categories/" class="site-header-nav-item" target="" title="分类">分类</a> <a href="https://blog.slienceme.cn/archives/" class="mobile-hidden site-header-nav-item" target="" title="归档">归档</a> <a href="https://blog.slienceme.cn/open-source/" class="mobile-hidden site-header-nav-item" target="" title="开源">开源</a> <a href="https://blog.slienceme.cn/fragments/" class="site-header-nav-item" target="" title="片段">片段</a> <a href="https://blog.slienceme.cn/wiki/" class="site-header-nav-item" target="" title="维基">维基</a> <a href="https://blog.slienceme.cn/links/" class="mobile-hidden site-header-nav-item" target="" title="链接">链接</a> <a href="https://blog.slienceme.cn/about/" class="site-header-nav-item" target="" title="关于">关于</a> <a class="mobile-hidden" href="https://blog.slienceme.cn/feed.xml"><span class="octicon octicon-rss" style="color:orange;"></span></a> </nav> </div> </header> <section class="collection-head small geopattern" data-pattern-id="机器学习｜【机器学习合集】模型"> <div class="container"> <div class="columns"> <div class="column three-fourths"> <div class="collection-title"> <h1 class="collection-header">机器学习｜【机器学习合集】模型设计之注意力机制</h1> <div class="collection-info"> <span class="meta-info"> <span class="octicon octicon-calendar"></span> 2023/10/31 </span> <span class="meta-info"> <span class="octicon octicon-file-directory"></span> <a href="https://blog.slienceme.cn/categories/#机器学习" title="机器学习">机器学习</a> </span> <span class="meta-info"> <span class="octicon octicon-clock"></span> 共 3386 字，约 10 分钟 </span> </div> </div> </div> <div class="column one-fourth mobile-hidden"> <div class="collection-title"> </div> </div> </div> </div> </section> <section class="container content"> <div class="columns"> <div class="column three-fourths" > <article class="article-content markdown-body"> <p><img src="https://blog.slienceme.cn/images/posts/logo_slienceme3.png" alt="img" /></p> <p>本文作者： <a href="https://slienceme.cn/">slience_me</a></p> <hr /> <h1 id="注意力机制">注意力机制</h1> <blockquote> <ul> <li>注意力机制（Attention Mechanism）是一种在深度学习模型中用于加强不同输入元素之间关联性的方法。它模拟了人类感知中的注意力过程，允许模型在处理数据时选择性地关注重要的信息，以提高性能。 以下是有关注意力机制在模型设计中的重要性和应用：</li> </ul> </blockquote> <blockquote> <ol> <li><code class="language-plaintext highlighter-rouge">自然语言处理（NLP）</code>： <ul> <li>在自然语言处理中，注意力机制常用于机器翻译、文本摘要、问答等任务。通过注意力机制，模型可以在生成输出时关注输入序列中与当前生成标记相关的部分。</li> <li>注意力机制有助于提高翻译质量，生成更准确的摘要，以及在问答任务中定位正确的上下文信息。</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">计算机视觉</code>： <ul> <li>在计算机视觉中，注意力机制可以用于目标检测、图像分类和图像分割。通过注意力机制，模型可以在处理图像时关注与任务相关的图像区域或特征。</li> <li>这有助于改善目标检测的准确性，特别是在多目标场景中，以及提高图像分类性能。</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">强化学习</code>： <ul> <li>在强化学习中，注意力机制可以用于选择执行动作的策略。模型可以在每个时间步上选择性地关注不同状态或观察，以优化决策。</li> <li>注意力机制在增强学习中的应用可以提高智能体的性能，特别是在复杂环境中的任务。</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">自动编码器和生成对抗网络</code>： <ul> <li>注意力机制还可以用于自动编码器（Autoencoders）和生成对抗网络（GANs）等模型，以改善特征提取和生成过程。</li> <li>通过引入注意力机制，模型可以更好地选择和生成重要的特征或样本。</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">跨模态任务</code>： <ul> <li>在处理跨模态数据（例如，文本和图像的关联）时，注意力机制可以帮助模型在不同模态之间建立关联，以实现更精确的任务。</li> </ul> </li> </ol> </blockquote> <blockquote> <ul> <li>总之，注意力机制是深度学习模型设计中的一个重要组成部分，可以提高模型的性能、可解释性和适应性。通过引入注意力机制，模型可以更有效地处理大量信息，选择性地关注重要信息，并在各种任务中获得更好的结果。因此，注意力机制已成为各种深度学习任务中的不可或缺的工具。 <h2 id="1-注意力机制及其应用">1. 注意力机制及其应用</h2> <h3 id="11-注意力机制的定义">1.1 注意力机制的定义</h3> </li> <li>&lt;font color=#E91E63&gt;<strong>Attention，对图像中不同区域或者句子中的不同部分给予不同的权重，从而找到感兴趣的区域，抑制不感兴趣区域</strong>&lt;/font&gt; <img src="https://blog.slienceme.cn/images/posts/7b5d2bdbc3584e8c91daea9d60a1cdec.png" alt="Alt Text" /> <h3 id="12-注意力机制的典型应用">1.2 注意力机制的典型应用</h3> </li> <li>&lt;font color=#E91E63&gt;<strong>显著目标检测，图像修复，图像编辑</strong>&lt;/font&gt; <img src="https://blog.slienceme.cn/images/posts/dcf102980cfd42c1b97146f00b9aa1ac.png" alt="Alt Text" /></li> <li>&lt;font color=#E91E63&gt;<strong>机器翻译，摘要生成，图像描述</strong>&lt;/font&gt; <img src="https://blog.slienceme.cn/images/posts/4dfcdaeb3c334c97977833d7da05b174.png" alt="Alt Text" /> <h2 id="2-注意力模型设计">2. 注意力模型设计</h2> <h3 id="21-空间注意力机制">2.1 空间注意力机制</h3> </li> <li>&lt;font color=#E91E63&gt;<strong>显著目标检测模型，Saliency Object Detection，预测显著目标概率图</strong>&lt;/font&gt; <img src="https://blog.slienceme.cn/images/posts/6d1c7a4a1d6a449a8898c399027c1d42.png" alt="Alt Text" /> <h3 id="22-空间注意力模型">2.2 空间注意力模型</h3> </li> <li>&lt;font color=#E91E63&gt;<strong>动态容量网络，Dynamic Capacity Networks</strong>&lt;/font&gt; <img src="https://blog.slienceme.cn/images/posts/327fa042ebee4b3aa669859bf39975e3.png" alt="Alt Text" /></li> <li>&lt;font color=#E91E63&gt;<strong>空间变换网络，STN(spatial transform network)</strong>&lt;/font&gt; <img src="https://blog.slienceme.cn/images/posts/1530afe9c9db406ea47a38967d83043f.png" alt="Alt Text" /> <h3 id="23-通道注意力机制">2.3 通道注意力机制</h3> </li> <li>&lt;font color=#E91E63&gt;<strong>SENet ,2017年ImageNet分类冠军网络</strong>&lt;/font&gt; <img src="https://blog.slienceme.cn/images/posts/6173d5bf2aca40569444b51f8d9f65be.png" alt="Alt Text" /> <h3 id="24-空间与通道注意力机制">2.4 空间与通道注意力机制</h3> </li> <li>&lt;font color=#E91E63&gt;<strong>CBAM，Convolutional Block Attention Module，同时从空间维度和通道维度进行Attention</strong>&lt;/font&gt; <img src="https://blog.slienceme.cn/images/posts/0699859ce7a749d8a9805ffe8b64b7e9.png" alt="Alt Text" /> <h3 id="25-自注意力机制">2.5 自注意力机制</h3> </li> <li>&lt;font color=#E91E63&gt;<strong>双线性模型，使用特征外积操作获得自注意力矩阵</strong>&lt;/font&gt; <img src="https://blog.slienceme.cn/images/posts/42962a6840b8463596ead8025963953b.png" alt="Alt Text" /></li> <li>&lt;font color=#E91E63&gt;<strong>非局部卷积，Non-local Network</strong>&lt;/font&gt; <img src="https://blog.slienceme.cn/images/posts/3e5f907827af4460b95ee031cc6b4777.png" alt="Alt Text" /> <h3 id="25-级联attention">2.5 级联attention</h3> </li> <li>&lt;font color=#E91E63&gt;<strong>Residual Attention Network(2018)</strong>&lt;/font&gt; <img src="https://blog.slienceme.cn/images/posts/40410551af9a4ef4a8e45fb5fad2d016.png" alt="Alt Text" /></li> </ul> </blockquote> <h1 id="动态网络">动态网络</h1> <blockquote> <ul> <li>动态网络（Dynamic Network）是一种神经网络架构，与传统的静态神经网络不同，它允许在模型训练和推理期间根据输入数据的特性动态调整网络结构。这种灵活性可以帮助网络更好地适应不同数据分布和任务需求。以下是一些关于动态网络的设计和应用方面的考虑：</li> </ul> </blockquote> <blockquote> <ol> <li><code class="language-plaintext highlighter-rouge">自适应结构</code>： <ul> <li>在动态网络中，网络结构可以根据输入数据的特性自动调整。这意味着网络可以动态地添加或删除层、模块或通道，以适应不同的输入数据。</li> <li>自适应结构可以提高模型的泛化性能，使其更适合于变化的数据分布，特别是在面对不平衡数据或噪声数据时。</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">注意机制</code>： <ul> <li>动态网络通常使用注意力机制（Attention Mechanism），以根据输入数据的不同部分调整网络的关注度。这有助于模型更好地关注重要的信息。</li> <li>注意机制在自然语言处理（NLP）和计算机视觉中的动态网络中得到广泛应用，例如，自然语言问答和图像标注任务。</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">遗忘机制</code>： <ul> <li>一些动态网络可以学习遗忘不需要的信息，从而提高模型的效率。这在处理长序列或大型数据时尤其有用。</li> <li>遗忘机制可以降低模型的计算复杂度，同时保持高性能。</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">模块化设计</code>： <ul> <li>动态网络通常采用模块化的设计，模块可以根据需要堆叠或重复。这种设计使得网络更易于扩展和调整。</li> <li>模块化设计对于构建可重复使用的模型部分和快速迭代设计是有利的。</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">预测网络结构</code>： <ul> <li>有些动态网络可以预测网络的结构，以更好地适应特定任务。这通常涉及到使用强化学习等方法来优化网络的结构。</li> <li>预测网络结构的方法对于模型设计的自动化和优化非常有前景。</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">实时决策</code>： <ul> <li>动态网络可以用于实时决策，例如自动驾驶、机器人控制或游戏决策，因为它们能够根据实时输入进行动态调整。</li> </ul> </li> </ol> </blockquote> <blockquote> <ul> <li>总之，动态网络是一种具有适应性和灵活性的神经网络架构，可以根据不同的任务和输入数据自动或手动地调整网络结构。这种灵活性使动态网络适用于各种不同的应用领域，尤其是需要适应变化的数据和任务要求的情况。 <h2 id="1-动态网络的定义">1. 动态网络的定义</h2> </li> </ul> </blockquote> <ul> <li> <p>&lt;font color=#E91E63&gt;<strong>网络结构在训练或推理时表现出不同的结构、对不同的样本，表现出不同</strong>&lt;/font&gt; <img src="https://blog.slienceme.cn/images/posts/cd71dab69b5a4d41a8d5b7aa594a1229.png" alt="Alt Text" /></p> </li> <li>&lt;font color=#E91E63&gt;<strong>研究动态网络原因：提高模型的泛化能力，减少计算量</strong>&lt;/font&gt; <img src="https://blog.slienceme.cn/images/posts/8eb23faade1b42d8a62b4fa447bce38d.png" alt="Alt Text" /> <h2 id="2-基于丢弃策略的动态网络">2. 基于丢弃策略的动态网络</h2> <h3 id="21-随机深度残差网络">2.1 随机深度残差网络</h3> </li> <li>&lt;font color=#E91E63&gt;<strong>残差网络可以看作是多个不同深度模型的集成，“Residual networks behave like ensembles of relatively shallow networks”</strong>&lt;/font&gt; <img src="https://blog.slienceme.cn/images/posts/77bd588fb626478f8a4bf72d5838fe57.png" alt="Alt Text" /> <h3 id="22-模块丢弃残差网络">2.2 模块丢弃残差网络</h3> </li> <li>&lt;font color=#E91E63&gt;<strong>Blockdrop，学习丢弃策略的残差模块</strong>&lt;/font&gt; <img src="https://blog.slienceme.cn/images/posts/e86ebae18529434d838d14d54ff2e1a5.png" alt="Alt Text" /> <h3 id="23-branchynet网络">2.3 BranchyNet网络</h3> </li> <li>&lt;font color=#E91E63&gt;<strong>对于不同的样本，根据累积的嫡来决定是否提前退出推理，越简单的样本，计算量越小</strong>&lt;/font&gt; <img src="https://blog.slienceme.cn/images/posts/08aff37c95254254b75cb053720c9b1c.png" alt="Alt Text" /> <h3 id="24-spatially-adaptive-computing-timesact">2.4 Spatially Adaptive Computing Time(SACT)</h3> </li> <li>&lt;font color=#E91E63&gt;<strong>对每一个残差单元的输出添加一个分支，用于预测halting score(累积概率，0~1)</strong>&lt;/font&gt; <img src="https://blog.slienceme.cn/images/posts/f768e937ccb44bea931147f7a399edac.png" alt="Alt Text" /> <h2 id="3-基于注意力机制的动态网络">3. 基于注意力机制的动态网络</h2> <h3 id="31-动态卷积dynamic-convolution">3.1 动态卷积(Dynamic Convolution)</h3> </li> <li>&lt;font color=#E91E63&gt;<strong>根据输入图像，采用注意力机制自适应地调整卷积参数</strong>&lt;/font&gt; <img src="https://blog.slienceme.cn/images/posts/dda4df864f0b4e6c9fce7b445efde789.png" alt="Alt Text" /> <h3 id="32-动态空间模型dynamic-regionaware-convolution">3.2 动态空间模型(Dynamic RegionAware Convolution)</h3> </li> <li>&lt;font color=#E91E63&gt;<strong>根据输入图像不同特征图上不同区域，采用不同的卷积核进行计算</strong>&lt;/font&gt; <img src="https://blog.slienceme.cn/images/posts/5a8aa11955f3454d9803bc1c71cc7d8b.png" alt="Alt Text" /> <h2 id="4-基于合并策略的动态网络">4. 基于合并策略的动态网络</h2> <h3 id="41-deep-rebirth">4.1 Deep Rebirth</h3> </li> <li>&lt;font color=#E91E63&gt;<strong>合并非tensor层，包括BN层，Pooling , Scale层，以及多个分支</strong>&lt;/font&gt; <img src="https://blog.slienceme.cn/images/posts/51ec0a4cb0dd4295a4bf315497dbd3cd.png" alt="Alt Text" /> <h3 id="42-repvgg">4.2 RepVGG</h3> </li> <li>&lt;font color=#E91E63&gt;<strong>训练时存在跳层连接，训练后合并连接</strong>&lt;/font&gt; <img src="https://blog.slienceme.cn/images/posts/845d28cd2d9146a09c8665b9197e3b37.png" alt="Alt Text" /></li> </ul> <p><strong>注：部分内容来自阿里云天池</strong></p> <div style="margin-top:2em;padding:0 1.5em;border:1px solid #d3d3d3;background-color:#deebf7"> <h3>文档信息</h3> <ul> <li>本文作者：<a href="https://blog.slienceme.cn" target="_blank">slience_me</a></li> <li>本文链接：<a href="https://blog.slienceme.cn/2023/10/31/%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6&%E5%8A%A8%E6%80%81%E7%BD%91%E7%BB%9C/" target="_blank">https://blog.slienceme.cn/2023/10/31/%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1%E4%B9%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6&%E5%8A%A8%E6%80%81%E7%BD%91%E7%BB%9C/</a></li> <li>版权声明：自由转载-非商用-非衍生-保持署名（<a href="http://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank">创意共享3.0许可证</a>）</li> </ul> </div> </article> <div class="share"> <div class="share-component" data-disabled='qq,facebook'></div> </div> <div class="comment"> <script src="https://giscus.app/client.js" data-repo="slience-me/blog-comments" data-repo-id="R_kgDOKr27jA" data-category="Announcements" data-category-id="DIC_kwDOKr27jM4CnWMe" data-mapping="title" data-strict="1" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="zh-CN" data-loading="lazy" crossorigin="anonymous" async> </script> </div> </div> <div class="column one-fourth"> <h3>Search</h3> <div id="site_search"> <div id="docsearch"> <input style="width:96%" type="text" id="search_box" placeholder="Search"> </div> </div> <script src="https://cdn.jsdelivr.net/npm/@docsearch/js@3"></script> <script type="text/javascript"> docsearch({ appId: "8W5T6R2WWG", apiKey: "e56e511c7c9f85e2c97e2817664aafb2", indexName: "doc", container: "#docsearch" }); </script> <h3 class="post-directory-title mobile-hidden">Table of Contents</h3> <div id="post-directory-module" class="mobile-hidden"> <section class="post-directory"> <dl></dl> </section> </div> <script src="https://blog.slienceme.cn/assets/js/jquery.toc.js"></script> </div> </div> </section> <footer class="container"> <div class="site-footer" role="contentinfo"> <div class="copyright left mobile-block"> <div style="display: flex;align-items: center;justify-content: center;"> <img src="/images/logo/logo.png" class="w-full" style="height: 10px;width: 10px;" alt="logo" />;"> <p> <a href="https://beian.mps.gov.cn/" rel="noreferrer" target="_blank">冀公网安备13102202000626</a> | <a href="https://beian.miit.gov.cn/" target="_blank" rel="noreferrer">津ICP备2024026565号-1</a> </p> </div> <p style="display: flex;align-items: center;justify-content: center;"> Copyright © 2019-present slience_me </p> <a href="javascript:window.scrollTo(0,0)" class="right mobile-visible">TOP</a> </div> <ul class="site-footer-links right mobile-hidden"> <li> <a href="javascript:window.scrollTo(0,0)" >TOP</a> </li> </ul> <br/> <script defer src="https://vercount.one/js"></script> <div class="mobile-hidden" style="margin-top:8px"> <span id="busuanzi_container_site_pv" style="display:none"> 本站访问量<span id="busuanzi_value_site_pv"></span>次 </span> <span id="busuanzi_container_site_uv" style="display:none"> / 本站访客数<span id="busuanzi_value_site_uv"></span>人 </span> <span id="busuanzi_container_page_pv" style="display:none"> / 本页访问量<span id="busuanzi_value_page_pv"></span>次 / 统计始于2024-12-01 </span> </div> </div> </footer> <div class="tools-wrapper"> <a class="gotop" href="#" title="回到顶部"><span class="octicon octicon-arrow-up"></span></a> </div> <script src="https://blog.slienceme.cn/assets/vendor/share.js/dist/js/share.min.js"></script> <script src="https://blog.slienceme.cn/assets/js/geopattern.js"></script> <script> jQuery(document).ready(function($) { $('.geopattern').each(function(){ $(this).geopattern($(this).data('pattern-id')); }); /* hljs.initHighlightingOnLoad(); */ }); </script> </body> </html>
