<!DOCTYPE html> <html lang="zh-cmn-Hans" prefix="og: http://ogp.me/ns#" class="han-init"> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" /> <title>机器学习｜【机器学习合集】人脸表情分类任务Pytorch实现 &mdash; Slience_me的博客</title> <link rel="stylesheet" href="https://slienceme.cn/assets/vendor/primer-css/css/primer.css"> <link rel="stylesheet" href="https://slienceme.cn/assets/css/components/collection.css"> <link rel="stylesheet" href="https://slienceme.cn/assets/css/components/repo-card.css"> <link rel="stylesheet" href="https://slienceme.cn/assets/css/sections/repo-list.css"> <link rel="stylesheet" href="https://slienceme.cn/assets/css/components/boxed-group.css"> <link rel="stylesheet" href="https://slienceme.cn/assets/css/globals/common.css"> <link rel="stylesheet" href="https://slienceme.cn/assets/css/globals/responsive.css"> <link rel="stylesheet" href="https://slienceme.cn/assets/css/posts/index.css"> <link rel="stylesheet" href="https://slienceme.cn/assets/vendor/octicons/octicons/octicons.css"> <link rel="stylesheet" href="https://mazhuang.org/rouge-themes/dist/github.css"> <link rel="stylesheet" href="https://slienceme.cn/assets/vendor/share.js/dist/css/share.min.css"> <link rel="canonical" href="https://slienceme.cn/2023/10/26/%E4%BA%BA%E8%84%B8%E8%A1%A8%E6%83%85%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1Pytorch%E5%AE%9E%E7%8E%B0&TensorBoardX%E7%9A%84%E4%BD%BF%E7%94%A8/"> <link rel="alternate" type="application/atom+xml" title="Slience_me的博客" href="https://slienceme.cn/feed.xml"> <link rel="shortcut icon" href="https://slienceme.cn/favicon.ico"> <meta property="og:title" content="机器学习｜【机器学习合集】人脸表情分类任务Pytorch实现"> <meta name="keywords" content="机器学习"> <meta name="og:keywords" content="机器学习"> <meta name="description" content="人脸表情分类任务"> <meta name="og:description" content="人脸表情分类任务"> <meta property="og:url" content="https://slienceme.cn/2023/10/26/%E4%BA%BA%E8%84%B8%E8%A1%A8%E6%83%85%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1Pytorch%E5%AE%9E%E7%8E%B0&TensorBoardX%E7%9A%84%E4%BD%BF%E7%94%A8/"> <meta property="og:site_name" content="Slience_me的博客"> <meta property="og:type" content="article"> <meta property="og:locale" content="zh_CN" /> <meta property="article:published_time" content="2023-10-26"> <meta name="google-site-verification" content="2feHjT1GNs1Yi2JQfOtdYx7d048naG_-cMwZaDAopIA" /> <script src="https://slienceme.cn/assets/vendor/jquery/dist/jquery.min.js"></script> <script src="https://slienceme.cn/assets/js/main.js"></script> </head> <body class="" data-mz=""> <header class="site-header"> <div class="container"> <h1><a href="https://slienceme.cn/" title="Slience_me的博客"><span class="octicon octicon-mark-github"></span> Slience_me的博客</a></h1> <button class="collapsed mobile-visible" type="button" onclick="toggleMenu();"> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button> <nav class="site-header-nav" role="navigation"> <a href="https://slienceme.cn/" class="site-header-nav-item" target="" title="首页">首页</a> <a href="https://slienceme.cn/categories/" class="site-header-nav-item" target="" title="分类">分类</a> <a href="https://slienceme.cn/archives/" class="mobile-hidden site-header-nav-item" target="" title="归档">归档</a> <a href="https://slienceme.cn/open-source/" class="mobile-hidden site-header-nav-item" target="" title="开源">开源</a> <a href="https://slienceme.cn/fragments/" class="site-header-nav-item" target="" title="片段">片段</a> <a href="https://slienceme.cn/wiki/" class="site-header-nav-item" target="" title="维基">维基</a> <a href="https://slienceme.cn/links/" class="mobile-hidden site-header-nav-item" target="" title="链接">链接</a> <a href="https://slienceme.cn/about/" class="site-header-nav-item" target="" title="关于">关于</a> <a class="mobile-hidden" href="https://slienceme.cn/feed.xml"><span class="octicon octicon-rss" style="color:orange;"></span></a> </nav> </div> </header> <section class="collection-head small geopattern" data-pattern-id="机器学习｜【机器学习合集】人脸"> <div class="container"> <div class="columns"> <div class="column three-fourths"> <div class="collection-title"> <h1 class="collection-header">机器学习｜【机器学习合集】人脸表情分类任务Pytorch实现</h1> <div class="collection-info"> <span class="meta-info"> <span class="octicon octicon-calendar"></span> 2023/10/26 </span> <span class="meta-info"> <span class="octicon octicon-file-directory"></span> <a href="https://slienceme.cn/categories/#机器学习" title="机器学习">机器学习</a> </span> <span class="meta-info"> <span class="octicon octicon-clock"></span> 共 9083 字，约 26 分钟 </span> </div> </div> </div> <div class="column one-fourth mobile-hidden"> <div class="collection-title"> </div> </div> </div> </div> </section> <section class="container content"> <div class="columns"> <div class="column three-fourths" > <article class="article-content markdown-body"> <h2 id="人脸表情分类任务">人脸表情分类任务</h2> <ul> <li>注意：整个项目来自阿里云天池，下面是开发人员的联系方式，本人仅作为学习记录！！！</li> <li>该文章原因，学习该项目，完善注释内容，针对新版本的Pytorch进行部分代码调整</li> <li>本文章采用pytorch2.0.1版本，python3.10版本</li> </ul> <p><a href="https://github.com/longpeng2008/yousan.ai/tree/master/computer_vision/projects/classification/pytorch/simpleconv3">源码链接</a></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>这是一个使用pytorch实现的简单的2分类任务
项目结构：
    - net.py: 网络定义脚本
    - train.py：模型训练脚本
    - inference.py：模型推理脚本
    - run_train.sh 训练可执行文件
    - run_inference.sh 推理可执行文件
    
# Copyright 2019 longpeng2008. All Rights Reserved.
# Licensed under the Apache License, Version 2.0 (the "License");
# If you find any problem,please contact us longpeng2008to2012@gmail.com 
</code></pre></div></div> <h3 id="1-网络结构">1. 网络结构</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># coding:utf8
</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># 3层卷积神经网络simpleconv3定义
# 包括3个卷积层，3个BN层，3个ReLU激活层，3个全连接层
</span>
<span class="k">class</span> <span class="nc">simpleconv3</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="c1"># 初始化函数
</span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nclass</span><span class="p">):</span>
        <span class="c1"># 继承父类
</span>        <span class="nb">super</span><span class="p">(</span><span class="n">simpleconv3</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="c1"># 3通道 输入图片大小为3*48*48，输出特征图大小为12*23*23，卷积核大小为3*3，步长为2
</span>        <span class="s">'''
            输出特征图大小 = [(输入大小 - 卷积核大小) / 步长] + 1
            输入大小是 48x48
            卷积核大小是 3x3
            步长是 2
            将这些值代入公式，您将得到输出特征图的大小：
            输出特征图大小 = [(48 - 3) / 2] + 1 = (45 / 2) + 1 = 22.5 + 1 = 23
        '''</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># 批量标准化操作 12个特征通道
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
        <span class="c1"># 输入图片大小为12*23*23，输出特征图大小为24*11*11，卷积核大小为3*3，步长为2
</span>        <span class="s">'''
            输出特征图大小 = [(输入大小 - 卷积核大小) / 步长] + 1
            输入大小是 23x23
            卷积核大小是 3x3
            步长是 2
            将这些值代入公式，您将得到输出特征图的大小：
            输出特征图大小 = [(23 - 3) / 2] + 1 = (20 / 2) + 1 = 10 + 1 = 11
        '''</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># 批量标准化操作 24个特征通道
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span>
        <span class="c1"># 输入图片大小为24*11*11，输出特征图大小为48*5*5，卷积核大小为3*3，步长为2
</span>        <span class="s">'''
            输出特征图大小 = [(输入大小 - 卷积核大小) / 步长] + 1
            输入大小是 11x11
            卷积核大小是 3x3
            步长是 2
            将这些值代入公式，您将得到输出特征图的大小：
            输出特征图大小 = [(11 - 3) / 2] + 1 = (8 / 2) + 1 = 4 + 1 = 5
        '''</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># 批量标准化操作 48个特征通道
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">bn3</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">48</span><span class="p">)</span>
        <span class="c1"># 输入向量长为48*5*5=1200，输出向量长为1200 展平
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">48</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1200</span><span class="p">)</span>
        <span class="c1"># 1200 -&gt; 128
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1200</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>  <span class="c1"># 输入向量长为1200，输出向量长为128
</span>        <span class="c1"># 128 -&gt; 类别数
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">nclass</span><span class="p">)</span>  <span class="c1"># 输入向量长为128，输出向量长为nclass，等于类别数
</span>
    <span class="c1"># 前向函数
</span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># relu函数，不需要进行实例化，直接进行调用
</span>        <span class="c1"># conv，fc层需要调用nn.Module进行实例化
</span>        <span class="c1"># 先卷积后标准化再激活
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">bn1</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">bn2</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">bn3</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="c1"># 更改形状 改为1维
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">48</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">)</span>
        <span class="c1"># 全连接再激活
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">'__main__'</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">torch</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">48</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">simpleconv3</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="s">'''
    simpleconv3(
          (conv1): Conv2d(3, 12, kernel_size=(3, 3), stride=(2, 2))
          (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(12, 24, kernel_size=(3, 3), stride=(2, 2))
          (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(24, 48, kernel_size=(3, 3), stride=(2, 2))
          (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (fc1): Linear(in_features=1200, out_features=1200, bias=True)
          (fc2): Linear(in_features=1200, out_features=128, bias=True)
          (fc3): Linear(in_features=128, out_features=2, bias=True)
    )
    '''</span>
</code></pre></div></div> <h3 id="2-训练函数">2. 训练函数</h3> <p>部分代码内容与作者不同</p> <ul> <li>scheduler.step()与optimizer.step()修改前后顺序</li> <li>RandomSizedCrop改为RandomCrop</li> <li>transforms.Scale修改为transforms.Resize</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># coding:utf8
</span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">division</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>
<span class="c1"># 使用tensorboardX进行可视化
</span><span class="kn">from</span> <span class="nn">tensorboardX</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">lr_scheduler</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>

<span class="kn">from</span> <span class="nn">net</span> <span class="kn">import</span> <span class="n">simpleconv3</span>

<span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="s">'logs'</span><span class="p">)</span>  <span class="c1"># 创建一个SummaryWriter的示例，默认目录名字为runs
</span>
<span class="c1"># 训练主函数
</span><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">):</span>
    <span class="s">"""
    训练模型
    Args:
        model: 模型
        criterion: loss函数
        optimizer: 优化器
        scheduler: 学习率调度器
        num_epochs: 训练轮次
    Returns:
    """</span>
    <span class="c1"># 开始训练
</span>    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="c1"># 打印训练轮次
</span>        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">phase</span> <span class="ow">in</span> <span class="p">[</span><span class="s">'train'</span><span class="p">,</span> <span class="s">'val'</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s">'train'</span><span class="p">:</span>
                <span class="c1"># 设置为训练模式
</span>                <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># 设置为验证模式
</span>                <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
            <span class="c1"># 损失变量
</span>            <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="c1"># 精度变量
</span>            <span class="n">running_accs</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">number_batch</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># 从dataloaders中获得数据
</span>            <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataloaders</span><span class="p">[</span><span class="n">phase</span><span class="p">]:</span>
                <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
                <span class="k">if</span> <span class="n">use_gpu</span><span class="p">:</span>
                    <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">.</span><span class="n">cuda</span><span class="p">()</span>
                    <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">.</span><span class="n">cuda</span><span class="p">()</span>
                <span class="c1"># 清空梯度
</span>                <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="c1"># 前向运行
</span>                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
                <span class="c1"># 使用max()函数对输出值进行操作，得到预测值索引
</span>                <span class="n">_</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="c1"># 计算损失
</span>                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s">'train'</span><span class="p">:</span>
                    <span class="c1"># 误差反向传播
</span>                    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
                    <span class="c1"># 参数更新
</span>                    <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
                <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">running_accs</span> <span class="o">+=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">labels</span><span class="p">).</span><span class="n">item</span><span class="p">()</span>
                <span class="n">number_batch</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="c1"># 调整学习率
</span>            <span class="n">scheduler</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
            <span class="c1"># 得到每一个epoch的平均损失与精度
</span>            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="n">running_loss</span> <span class="o">/</span> <span class="n">number_batch</span>
            <span class="n">epoch_acc</span> <span class="o">=</span> <span class="n">running_accs</span> <span class="o">/</span> <span class="n">dataset_sizes</span><span class="p">[</span><span class="n">phase</span><span class="p">]</span>

            <span class="c1"># 收集精度和损失用于可视化
</span>            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s">'train'</span><span class="p">:</span>
                <span class="n">writer</span><span class="p">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s">'data/trainloss'</span><span class="p">,</span> <span class="n">epoch_loss</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
                <span class="n">writer</span><span class="p">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s">'data/trainacc'</span><span class="p">,</span> <span class="n">epoch_acc</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">writer</span><span class="p">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s">'data/valloss'</span><span class="p">,</span> <span class="n">epoch_loss</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
                <span class="n">writer</span><span class="p">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s">'data/valacc'</span><span class="p">,</span> <span class="n">epoch_acc</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>

            <span class="k">print</span><span class="p">(</span><span class="s">'{} Loss: {:.4f} Acc: {:.4f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span>
                <span class="n">phase</span><span class="p">,</span> <span class="n">epoch_loss</span><span class="p">,</span> <span class="n">epoch_acc</span><span class="p">))</span>
    <span class="n">writer</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">model</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">'__main__'</span><span class="p">:</span>

    <span class="c1"># 图像统一缩放大小
</span>    <span class="n">image_size</span> <span class="o">=</span> <span class="mi">60</span>
    <span class="c1"># 图像裁剪大小，即训练输入大小
</span>    <span class="n">crop_size</span> <span class="o">=</span> <span class="mi">48</span>
    <span class="c1"># 分类类别数
</span>    <span class="n">nclass</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="c1"># 创建模型
</span>    <span class="n">model</span> <span class="o">=</span> <span class="n">simpleconv3</span><span class="p">(</span><span class="n">nclass</span><span class="p">)</span>
    <span class="c1"># 数据目录
</span>    <span class="n">data_dir</span> <span class="o">=</span> <span class="s">'./data'</span>

    <span class="c1"># 模型缓存接口
</span>    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">exists</span><span class="p">(</span><span class="s">'models'</span><span class="p">):</span>
        <span class="n">os</span><span class="p">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s">'models'</span><span class="p">)</span>

    <span class="c1"># 检查GPU是否可用，如果是使用GPU，否使用CPU
</span>    <span class="n">use_gpu</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">use_gpu</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">cuda</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

    <span class="c1"># 创建数据预处理函数，训练预处理包括随机裁剪缩放、随机翻转、归一化，验证预处理包括中心裁剪，归一化
</span>    <span class="n">data_transforms</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">'train'</span><span class="p">:</span> <span class="n">transforms</span><span class="p">.</span><span class="n">Compose</span><span class="p">([</span>
            <span class="n">transforms</span><span class="p">.</span><span class="n">RandomCrop</span><span class="p">(</span><span class="mi">48</span><span class="p">),</span>  <span class="c1"># 随机大小、长宽比裁剪图片size=48 RandomSizedCrop改为RandomCrop
</span>            <span class="n">transforms</span><span class="p">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>  <span class="c1"># 随机水平翻转 默认概率p=0.5
</span>            <span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">(),</span>  <span class="c1"># 将原始的PILImage格式或者numpy.array格式的数据格式化为可被pytorch快速处理的张量类型
</span>            <span class="n">transforms</span><span class="p">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>  <span class="c1"># 数据标准化 要将图像三个通道的数据 整理到 [-1,1] 之间 ，可以加快模型的收敛
</span>        <span class="p">]),</span>
        <span class="s">'val'</span><span class="p">:</span> <span class="n">transforms</span><span class="p">.</span><span class="n">Compose</span><span class="p">([</span>
            <span class="n">transforms</span><span class="p">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">64</span><span class="p">),</span>  <span class="c1"># Scale用于调整图像的大小，现在采用transforms.Resize()代替
</span>            <span class="n">transforms</span><span class="p">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">48</span><span class="p">),</span>  <span class="c1"># 从图像中心裁剪图片尺寸size=48
</span>            <span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">(),</span>
            <span class="n">transforms</span><span class="p">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
        <span class="p">]),</span>
    <span class="p">}</span>

    <span class="c1"># 使用torchvision的dataset ImageFolder接口读取数据
</span>    <span class="n">image_datasets</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">datasets</span><span class="p">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="n">data_transforms</span><span class="p">[</span><span class="n">x</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s">'train'</span><span class="p">,</span> <span class="s">'val'</span><span class="p">]}</span>

    <span class="c1"># 创建数据指针，设置batch大小，shuffle，多进程数量
</span>    <span class="n">dataloaders</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">image_datasets</span><span class="p">[</span><span class="n">x</span><span class="p">],</span>
                                                  <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>  <span class="c1"># 每个小批次包含16个样本
</span>                                                  <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>   <span class="c1"># 是否随机打乱数据
</span>                                                  <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>  <span class="c1"># 加载数据的子进程数
</span>                   <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s">'train'</span><span class="p">,</span> <span class="s">'val'</span><span class="p">]}</span>
    <span class="c1"># 获得数据集大小
</span>    <span class="n">dataset_sizes</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">image_datasets</span><span class="p">[</span><span class="n">x</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s">'train'</span><span class="p">,</span> <span class="s">'val'</span><span class="p">]}</span>

    <span class="c1"># 优化目标使用交叉熵，优化方法使用带动量项的SGD，学习率迭代策略为step，每隔100个epoch，变为原来的0.1倍
</span>    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="c1"># 优化器 传入权重阈值，学习率0.1 动量（momentum）是一个控制梯度下降方向的超参数。
</span>    <span class="c1"># 它有助于加速训练，特别是在存在平坦区域或局部极小值时。动量的值通常在0到1之间。较大的动量值会使参数更新更平滑。在这里，动量设置为0.9。
</span>    <span class="n">optimizer_ft</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

    <span class="s">'''
    
    lr_scheduler.StepLR 是PyTorch中的学习率调度器（learning rate scheduler），用于在训练神经网络时动态调整学习率。
    lr_scheduler.StepLR 允许您在训练的不同阶段逐步减小学习率，以帮助优化过程。
    optimizer_ft：这是您用于优化模型参数的优化器，通常是 optim.SGD 或其他PyTorch优化器的实例。
                学习率调度器将监控这个优化器的状态，并根据其规则更新学习率。
    step_size=100：这是学习率更新的周期，也称为学习率下降步数。在每个 step_size 个训练周期之后，学习率将减小。
            gamma=0.1：这是学习率减小的因子。在每个 step_size 个训练周期之后，学习率将乘以 gamma。这意味着学习率将以 gamma 的倍数逐步减小。
    '''</span>
    <span class="n">exp_lr_scheduler</span> <span class="o">=</span> <span class="n">lr_scheduler</span><span class="p">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer_ft</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                        <span class="n">criterion</span><span class="o">=</span><span class="n">criterion</span><span class="p">,</span>
                        <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer_ft</span><span class="p">,</span>
                        <span class="n">scheduler</span><span class="o">=</span><span class="n">exp_lr_scheduler</span><span class="p">,</span>
                        <span class="n">num_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

    <span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s">'models/model.pt'</span><span class="p">)</span>
</code></pre></div></div> <h3 id="3-预测">3. 预测</h3> <p>执行以下内容，或者自行安排数据集</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">## 使用方法 python3 inference.py 模型路径 图片路径
</span><span class="n">python3</span> <span class="n">inference</span><span class="p">.</span><span class="n">py</span> <span class="n">models</span><span class="o">/</span><span class="n">model</span><span class="p">.</span><span class="n">pt</span> <span class="n">data</span><span class="o">/</span><span class="n">train</span><span class="o">/</span><span class="mi">0</span><span class="o">/</span><span class="mi">1</span><span class="n">neutral</span><span class="p">.</span><span class="n">jpg</span>
<span class="n">python3</span> <span class="n">inference</span><span class="p">.</span><span class="n">py</span> <span class="n">models</span><span class="o">/</span><span class="n">model</span><span class="p">.</span><span class="n">pt</span> <span class="n">data</span><span class="o">/</span><span class="n">train</span><span class="o">/</span><span class="mi">1</span><span class="o">/</span><span class="mi">1</span><span class="n">smile</span><span class="p">.</span><span class="n">jpg</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># coding:utf8
</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>

<span class="c1"># 全局变量
# sys.argv[1] 权重文件
# sys.argv[2] 图像文件夹
</span>
<span class="n">testsize</span> <span class="o">=</span> <span class="mi">48</span>  <span class="c1"># 测试图大小
</span><span class="kn">from</span> <span class="nn">net</span> <span class="kn">import</span> <span class="n">simpleconv3</span>

<span class="c1"># 定义模型
</span><span class="n">net</span> <span class="o">=</span> <span class="n">simpleconv3</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="c1"># 设置推理模式，使得dropout和batchnorm等网络层在train和val模式间切换
</span><span class="n">net</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
<span class="c1"># 停止autograd模块的工作，以起到加速和节省显存
</span><span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">()</span>

<span class="c1"># 载入模型权重
</span><span class="n">modelpath</span> <span class="o">=</span> <span class="n">sys</span><span class="p">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">net</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">modelpath</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="k">lambda</span> <span class="n">storage</span><span class="p">,</span> <span class="n">loc</span><span class="p">:</span> <span class="n">storage</span><span class="p">))</span>

<span class="c1"># 定义预处理函数
</span><span class="n">data_transforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="p">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">48</span><span class="p">),</span>
    <span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="p">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])])</span>

<span class="c1"># 读取3通道图片，并扩充为4通道tensor
</span><span class="n">imagepath</span> <span class="o">=</span> <span class="n">sys</span><span class="p">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="n">imagepath</span><span class="p">)</span>
<span class="n">imgblob</span> <span class="o">=</span> <span class="n">data_transforms</span><span class="p">(</span><span class="n">image</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># 获得预测结果predict，得到预测的标签值label
</span><span class="n">predict</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">imgblob</span><span class="p">)</span>
<span class="n">index</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predict</span><span class="p">.</span><span class="n">detach</span><span class="p">().</span><span class="n">numpy</span><span class="p">())</span>
<span class="c1"># print(predict)
# print(index)
</span>
<span class="k">if</span> <span class="n">index</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'the predict of '</span> <span class="o">+</span> <span class="n">sys</span><span class="p">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="s">' is '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="s">'none'</span><span class="p">))</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'the predict of '</span> <span class="o">+</span> <span class="n">sys</span><span class="p">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="s">' is '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="s">'smile'</span><span class="p">))</span>
</code></pre></div></div> <h3 id="4-tensorboardx的使用">4. TensorBoardX的使用</h3> <p>TensorBoardX 是一个用于在 PyTorch 中可视化训练过程和结果的工具。它是 TensorBoard 的 Python 版本，用于创建交互式、实时的训练和评估图表。以下是一些使用 TensorBoardX 的一般步骤：</p> <ol> <li> <p><strong>安装 TensorBoardX：首先，您需要安装 TensorBoardX 库。您可以使用以下命令安装它：</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install tensorboardX
</code></pre></div> </div> </li> <li> <p><strong>导入库：在您的 PyTorch 代码中，导入 TensorBoardX 库：</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from tensorboardX import SummaryWriter
</code></pre></div> </div> </li> <li> <p><strong>创建 SummaryWriter：创建一个 <code class="language-plaintext highlighter-rouge">SummaryWriter</code> 对象，以将日志数据写入 TensorBoard 日志目录。</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>writer = SummaryWriter()
</code></pre></div> </div> </li> <li> <p><strong>记录数据：在训练循环中，使用 <code class="language-plaintext highlighter-rouge">writer.add_*</code> 方法来记录各种数据，例如标量、图像、直方图等。以下是一些示例：</strong></p> <ul> <li> <p><strong>记录标量数据：</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>writer.add_scalar('loss', loss, global_step)
</code></pre></div> </div> </li> <li> <p><strong>记录图像数据：</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>writer.add_image('image', image, global_step)
</code></pre></div> </div> </li> <li> <p><strong>记录直方图数据：</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>writer.add_histogram('weights', model.conv1.weight, global_step)
</code></pre></div> </div> </li> <li> <p><strong>记录文本数据：</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>writer.add_text('description', 'This is a description.', global_step)
</code></pre></div> </div> </li> </ul> </li> <li> <p><strong>启动 TensorBoard 服务器：在命令行中，使用以下命令启动 TensorBoard 服务器：</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensorboard --logdir=/path/to/log/directory
</code></pre></div> </div> <p>其中 <code class="language-plaintext highlighter-rouge">/path/to/log/directory</code> 是存储 TensorBoardX 日志的目录。</p> </li> <li> <p><strong>查看可视化结果：在浏览器中打开 TensorBoard 的 Web 界面，通常位于 <code class="language-plaintext highlighter-rouge">http://localhost:6006</code>，您可以在该界面上查看可视化结果。</strong></p> </li> </ol> <p>请注意，您可以根据需要记录不同类型的数据，并根据训练过程的不同阶段定期记录数据。TensorBoardX 提供了丰富的可视化工具，以帮助您监视和分析模型的训练过程。</p> <p>确保在训练循环中适时记录数据，并使用 TensorBoardX 查看结果，以更好地理解和改进您的深度学习模型。</p> <hr /> <p>这是 TensorBoard 启动时的一般信息，表明TensorBoard运行在本地主机（localhost）。如果您想使 TensorBoard 可以在网络上访问，可以采取以下几种方法：</p> <ol> <li> <p><strong>使用代理</strong>：您可以使用代理服务器来将 TensorBoard 的端口暴露到网络上。这通常需要在代理服务器上进行一些配置，以便外部用户可以访问 TensorBoard。代理服务器可以是诸如 Nginx 或 Apache 之类的 Web 服务器。</p> </li> <li> <p><strong>使用 –bind_all 参数</strong>：在启动 TensorBoard 时，您可以使用 <code class="language-plaintext highlighter-rouge">--bind_all</code> 参数，以将 TensorBoard 绑定到所有网络接口。这样，TensorBoard 将可以在本地网络上的任何 IP 地址上访问，而不仅仅是本地主机。例如：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensorboard --logdir=/path/to/log/directory --bind_all
</code></pre></div> </div> </li> <li> <p><strong>使用 –host 参数</strong>：您还可以使用 <code class="language-plaintext highlighter-rouge">--host</code> 参数来指定 TensorBoard 的主机名（hostname），以使其在指定的主机上可用。例如：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensorboard --logdir=/path/to/log/directory --host=0.0.0.0
</code></pre></div> </div> <p>这将允许 TensorBoard 在所有网络接口上运行，从而在网络上的任何 IP 地址上访问。</p> </li> </ol> <p>请根据您的需求和网络设置选择适当的方法。如果只需要在本地访问 TensorBoard，无需进行任何更改。如果需要在网络上访问，可以使用上述选项之一。不过，请注意，为了安全起见，最好将 TensorBoard 限制在受信任的网络上，或者使用身份验证和授权来保护访问。</p> <hr /> <p><strong>效果展示</strong> <img src="https://slienceme.cn/images/posts/b5d2cf8b6060420398daee88e336544b.png" alt="在这里插入图片描述" /></p> <div style="margin-top:2em;padding:0 1.5em;border:1px solid #d3d3d3;background-color:#deebf7"> <h3>文档信息</h3> <ul> <li>本文作者：<a href="https://slienceme.cn" target="_blank">slience_me</a></li> <li>本文链接：<a href="https://slienceme.cn/2023/10/26/%E4%BA%BA%E8%84%B8%E8%A1%A8%E6%83%85%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1Pytorch%E5%AE%9E%E7%8E%B0&TensorBoardX%E7%9A%84%E4%BD%BF%E7%94%A8/" target="_blank">https://slienceme.cn/2023/10/26/%E4%BA%BA%E8%84%B8%E8%A1%A8%E6%83%85%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1Pytorch%E5%AE%9E%E7%8E%B0&TensorBoardX%E7%9A%84%E4%BD%BF%E7%94%A8/</a></li> <li>版权声明：自由转载-非商用-非衍生-保持署名（<a href="http://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank">创意共享3.0许可证</a>）</li> </ul> </div> </article> <div class="share"> <div class="share-component" data-disabled='qq,facebook'></div> </div> <div class="comment"> <script src="https://giscus.app/client.js" data-repo="slience-me/blog-comments" data-repo-id="MDEwOlJlcG9zaXRvcnk5MzEyNzkxNw==" data-category="Announcements" data-category-id="DIC_kwDOBY0E7c4CRtg9" data-mapping="title" data-strict="1" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="zh-CN" data-loading="lazy" crossorigin="anonymous" async> </script> </div> </div> <div class="column one-fourth"> <h3>Search</h3> <div id="site_search"> <input style="width:96%" type="text" id="search_box" placeholder="Search"> </div> <ul id="search_results" style="font-size:14px;list-style-type:none;padding-top:10px;padding-left:10px;"></ul> <script src="https://slienceme.cn/assets/js/simple-jekyll-search.min.js"></script> <script type="text/javascript"> SimpleJekyllSearch({ searchInput: document.getElementById('search_box'), resultsContainer: document.getElementById('search_results'), json: 'https://slienceme.cn/assets/search_data.json?v=1736474772', searchResultTemplate: '<li><a href="{url}" title="{title}">{title}</a></li>', noResultsText: 'No results found', limit: 10, fuzzy: false, exclude: ['Welcome'] }) </script> <h3 class="post-directory-title mobile-hidden">Table of Contents</h3> <div id="post-directory-module" class="mobile-hidden"> <section class="post-directory"> <dl></dl> </section> </div> <script src="https://slienceme.cn/assets/js/jquery.toc.js"></script> </div> </div> </section> <footer class="container"> <div class="site-footer" role="contentinfo"> <div class="copyright left mobile-block"> Copyright@ 2019-2025 slience_me 版权所有&emsp; <img src="/images/logo/logo.png" class="w-full" style="width: 12px;"> <a href="https://beian.mps.gov.cn/#/query/webSearch?code=13102202000626" rel="noreferrer" target="_blank">冀公网安备13102202000626</a>&emsp; <a href="https://beian.miit.gov.cn/#/Integrated/index" target="_blank" rel="noreferrer">津ICP备2024026565号-1</a> <a href="javascript:window.scrollTo(0,0)" class="right mobile-visible">TOP</a> </div> <ul class="site-footer-links right mobile-hidden"> <li> <a href="javascript:window.scrollTo(0,0)" >TOP</a> </li> </ul> <br/> <script async src="https://slienceme.cn/assets/vendor/busuanzi/2.3/busuanzi.pure.mini.js"></script> <div class="mobile-hidden" style="margin-top:8px"> <span id="busuanzi_container_site_pv" style="display:none"> 本站访问量<span id="busuanzi_value_site_pv"></span>次 </span> <span id="busuanzi_container_site_uv" style="display:none"> / 本站访客数<span id="busuanzi_value_site_uv"></span>人 </span> <span id="busuanzi_container_page_pv" style="display:none"> / 本页访问量<span id="busuanzi_value_page_pv"></span>次 / 统计始于2024-12-01 </span> </div> </div> </footer> <div class="tools-wrapper"> <a class="gotop" href="#" title="回到顶部"><span class="octicon octicon-arrow-up"></span></a> </div> <script src="https://slienceme.cn/assets/vendor/share.js/dist/js/share.min.js"></script> <script src="https://slienceme.cn/assets/js/geopattern.js"></script> <script> jQuery(document).ready(function($) { $('.geopattern').each(function(){ $(this).geopattern($(this).data('pattern-id')); }); /* hljs.initHighlightingOnLoad(); */ }); </script> </body> </html>
